{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8596073,
          "sourceType": "datasetVersion",
          "datasetId": 5142469
        }
      ],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ad1639b7138461f8ff12074bd44b17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c077bfe974a443d4be019332491c1e7d",
              "IPY_MODEL_3c9e32773723453aa3bbcd34e94db4bd",
              "IPY_MODEL_70b9fadcbd354676833e00978f2a8a65"
            ],
            "layout": "IPY_MODEL_f6b51678e2f74c79ad71b72a2108b51e"
          }
        },
        "c077bfe974a443d4be019332491c1e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef802be26b1c4067a29c56fae5f85267",
            "placeholder": "​",
            "style": "IPY_MODEL_07fbe5d72310480bad590611c27fee4e",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "3c9e32773723453aa3bbcd34e94db4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd25c89e596f4d769f9718138823583b",
            "max": 38,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b50e9afef654e9d8fceb3e59b246faa",
            "value": 38
          }
        },
        "70b9fadcbd354676833e00978f2a8a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_131765c097384fe6b35137554455cfca",
            "placeholder": "​",
            "style": "IPY_MODEL_9e9538f0f03f40a9a3cedb8ce1a904f0",
            "value": " 38/38 [00:11&lt;00:00,  3.27it/s]"
          }
        },
        "f6b51678e2f74c79ad71b72a2108b51e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "ef802be26b1c4067a29c56fae5f85267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07fbe5d72310480bad590611c27fee4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd25c89e596f4d769f9718138823583b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b50e9afef654e9d8fceb3e59b246faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "131765c097384fe6b35137554455cfca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e9538f0f03f40a9a3cedb8ce1a904f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/herrcult69/HME-Recognition-DSAI/blob/main/HME_recognition_ColabVersion_10423041.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "ntcuong2103_crohme2019_path = kagglehub.dataset_download('ntcuong2103/crohme2019')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "2KGe_J0_GomF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2066136b-9b31-47fb-9f28-307839e9a3a7"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# If it is failed, run the above cell again to fix\n",
        "assert ntcuong2103_crohme2019_path == \"/kaggle/input/crohme2019\"\n"
      ],
      "metadata": {
        "id": "6_aX0FAXHAjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CROHME Temporal Sequence Classification (CROHME-CTC) Baseline**"
      ],
      "metadata": {
        "id": "DEm0-zzfGomG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we will build and train a recurrent neural network (RNN) for translating handwritten mathematical expressions into sequence of symbols and relations based on Symbol Relation Tree and CROHME dataset.\n",
        "\n",
        "The model we'll be using is a simple RNN with a single layer of Bidirectional LSTM cells. We will use Connectionist Temporal Classification (CTC) loss to train the model.\n",
        "\n",
        "The model is trained on the CROHME dataset, which contains handwritten mathematical expressions in the form of Symbol Relation Trees. The dataset is preprocessed and converted into a sequence of symbols and relations, which is used as the input to the model.\n",
        "\n",
        "Your job is to feature engineer the input data and train the model to achieve the best performance possible. Additionally, consider implementing data augmentation techniques to enhance the training dataset."
      ],
      "metadata": {
        "id": "m_BtWPW5GomG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some features from the project:\n",
        "\n",
        "*   Public competition dataset: CROHME https://paperswithcode.com/dataset/crohme-2019\n",
        "*   Advance data preparation: time series feature extraction, collate function\n",
        "*   High level API of pytorch lightning\n",
        "*   Experiment tracking with Weight and Biases\n",
        "\n"
      ],
      "metadata": {
        "id": "neUWD9FsW3iU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "UjJVUXAGGomH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pytorch-lightning torchmetrics wandb\n",
        "# Install required packages for CUDA CTC Decoder\n",
        "!pip install torchaudio\n",
        "!pip install flashlight-text"
      ],
      "metadata": {
        "id": "f38o_eYpHTDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce40ce92-593b-4f1d-e555-8370800ccb70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/823.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\n",
            "Collecting flashlight-text\n",
            "  Downloading flashlight_text-0.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Downloading flashlight_text-0.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flashlight-text\n",
            "Successfully installed flashlight-text-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchmetrics.text import EditDistance\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
        "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import wandb\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from helper import *\n",
        "from collections.abc import Sequence\n",
        "from typing import Literal, Optional, Union\n",
        "\n",
        "import json\n",
        "# Add these imports to your import section\n",
        "import torchaudio\n",
        "from torchaudio.models.decoder import ctc_decoder"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T00:25:54.116606Z",
          "iopub.execute_input": "2025-05-20T00:25:54.116882Z",
          "iopub.status.idle": "2025-05-20T00:25:54.123208Z",
          "shell.execute_reply.started": "2025-05-20T00:25:54.116861Z",
          "shell.execute_reply": "2025-05-20T00:25:54.122454Z"
        },
        "id": "vrzqHX_hGomH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# mount crohme2019 -> dataset\n",
        "!ln -s /kaggle/input/crohme2019 dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T00:25:59.086626Z",
          "iopub.execute_input": "2025-05-20T00:25:59.086956Z",
          "iopub.status.idle": "2025-05-20T00:25:59.238737Z",
          "shell.execute_reply.started": "2025-05-20T00:25:59.08693Z",
          "shell.execute_reply": "2025-05-20T00:25:59.23784Z"
        },
        "id": "yUw3NzxEGomH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The above command created a symbolic link\n",
        "> dataset -> /kaggle/input/crohme2019\n",
        ">\n",
        "> We can now access the dataset from current directory instead of /kaggle/input"
      ],
      "metadata": {
        "id": "iwS9-TZBGomH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code for displaying current directory tree, you don't need to run.\n",
        "\n",
        "!sudo apt-get install tree\n",
        "!tree -L 3 dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T00:26:10.627244Z",
          "iopub.execute_input": "2025-05-20T00:26:10.627511Z",
          "iopub.status.idle": "2025-05-20T00:26:10.772621Z",
          "shell.execute_reply.started": "2025-05-20T00:26:10.627492Z",
          "shell.execute_reply": "2025-05-20T00:26:10.771799Z"
        },
        "id": "OZVH3nONGomH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404e40a8-f01e-4617-cb53-14170ff53abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 1s (62.8 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 126319 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[01;36mdataset\u001b[0m\n",
            "├── \u001b[01;34mcrohme2019\u001b[0m\n",
            "│   └── \u001b[01;34mcrohme2019\u001b[0m\n",
            "│       ├── \u001b[01;34mtest\u001b[0m\n",
            "│       ├── \u001b[01;34mtrain\u001b[0m\n",
            "│       └── \u001b[01;34mvalid\u001b[0m\n",
            "├── \u001b[00mcrohme2019_test.txt\u001b[0m\n",
            "├── \u001b[00mcrohme2019_train.txt\u001b[0m\n",
            "└── \u001b[00mcrohme2019_valid.txt\u001b[0m\n",
            "\n",
            "5 directories, 3 files\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview of the dataset"
      ],
      "metadata": {
        "id": "VFGrDs0lI0Gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the folder structure of the dataset.\n",
        "\n",
        "```\n",
        "dataset\n",
        "├── crohme2019\n",
        "│   └── crohme2019\n",
        "│       ├── test\n",
        "│       ├── train\n",
        "│       └── valid\n",
        "├── crohme2019_test.txt\n",
        "├── crohme2019_train.txt\n",
        "└── crohme2019_valid.txt\n",
        "```\n",
        "\n",
        "There are two parts:\n",
        "* Inkml files: XML based files containing handwriting data (sequences of handwritten strokes) captured from the devices.\n",
        "```\n",
        "dataset\n",
        "├── crohme2019\n",
        "│   └── crohme2019\n",
        "│       ├── test\n",
        "│       ├── train\n",
        "│       └── valid\n",
        "```\n",
        "* Annotation files: Containing the labels for each input handwriting samples.\n",
        "```\n",
        "dataset\n",
        "├── crohme2019_test.txt\n",
        "├── crohme2019_train.txt\n",
        "└── crohme2019_valid.txt\n",
        "```\n"
      ],
      "metadata": {
        "id": "EDsGmF07IuYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> An example of inkml file, the points (x, y coords) are recorded in each trace (handwritten stroke).\n",
        "\n",
        "```\n",
        "<ink xmlns=\"http://www.w3.org/2003/InkML\">\n",
        "<traceFormat>\n",
        "<channel name=\"X\" type=\"decimal\"/>\n",
        "<channel name=\"Y\" type=\"decimal\"/>\n",
        "</traceFormat>\n",
        "...\n",
        "\n",
        "<trace id=\"0\">\n",
        "241 123, 240 123, 239 123, 238 123, 237 123, 236 123, 236 122, 237 122, 238 122, 240 122, 242 122, 244 122, 247 122, 251 121, 254 121, 257 121, 260 120, 262 120, 265 120, 266 120, 267 120, 268 120, 269 120, 268 120\n",
        "</trace>\n",
        "<trace id=\"1\">\n",
        "301 123, 300 124, 299 124, 298 124, 297 124, 296 124, 295 124, 294 124, 295 124, 296 124, 297 124, 298 124, 299 123, 301 123, 302 123, 303 123, 304 122, 305 122, 306 122, 307 122, 308 122, 310 122, 311 122, 314 122, 316 121, 317 121, 319 121, 321 121, 323 121, 328 120, 330 120, 332 120, 333 120, 335 120, 336 120, 344 119, 346 119, 348 119, 350 119, 352 119, 357 119, 358 119, 360 119, 362 119, 364 119, 365 119, 370 119, 372 119, 373 119, 374 119, 375 119, 377 119, 377 118, 376 118, 374 118, 372 118\n",
        "</trace>\n",
        "<trace id=\"2\">\n",
        "318 89, 319 89, 320 89, 321 88, 323 87, 324 86, 325 84, 326 83, 327 82, 328 80, 329 79, 330 77, 331 75, 332 74, 333 73, 333 72, 333 73, 333 75, 333 76, 333 78, 333 80, 332 81, 332 83, 332 85, 332 86, 332 88, 332 90, 332 92, 332 93, 333 95, 333 97, 333 98, 333 100, 333 101, 333 102, 333 103, 333 104, 333 103, 333 101, 332 99\n",
        "</trace>\n",
        "<trace id=\"3\">\n",
        "302 148, 301 148, 302 147, 302 146, 303 145, 304 144, 305 143, 306 142, 307 140, 308 139, 308 138, 308 137, 308 136, 308 137, 308 138, 309 139, 309 140, 309 141, 309 142, 309 144, 309 146, 309 147, 309 149, 309 151, 309 153, 309 155, 309 157, 310 159, 310 162, 310 164, 310 169, 310 171, 310 172, 310 174, 311 175, 311 179, 311 180, 311 181, 311 182, 311 181\n",
        "</trace>\n",
        "...\n",
        "\n",
        "</ink>\n",
        "\n",
        "```\n",
        "\n",
        "> An example of annotation file: left part is inkml file path, right part is the label (target) for that inkml file.\n",
        "\n",
        "```\n",
        "...\n",
        "crohme2019/test/UN19_1041_em_597.inkml\t- Right \\sqrt Inside 2\n",
        "crohme2019/test/UN19_1019_em_256.inkml\ta Right n Right y\n",
        "crohme2019/test/UN19_1033_em_474.inkml\tV Sub n Right - Right 1 NoRel = Right \\int Right d Sup n Right - Right 1 NoRel x Right \\sqrt Inside h\n",
        "\n",
        "...\n",
        "```\n",
        "\n",
        "> The label is a sequence of **symbols** and **spatial relations** between symbols (based on writing order).\n",
        "\n"
      ],
      "metadata": {
        "id": "Jz5_G7uZJWfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Build Vocabulary\n",
        "\n",
        "Builds and manages a vocabulary for converting characters (tokens) to indices (encoding) and vice-versa (decoding). This is essential for processing text data in machine learning tasks, particularly for sequence-to-sequence models like those used in handwriting recognition or mathematical expression translation.\n",
        "\n",
        "In this project, the vocabulary is for encoding the target sequence (for example: \"- Right \\\\sqrt Inside 2\") into a sequence of indices ([5, 37, 74, 30, 10]). It is constructed from multiple annotation files (train, test, and validation sets) and includes a special blank character (this is for CTC loss). It supports encoding (tokens to indices) and decoding (indices to tokens) operations.\n",
        "\n",
        "\n",
        "> _You will need to build the `class Vocab` using the two functions provided. Also the vocabulary should be exported as a JSON file so that we can reuse it later in the dataset._\n",
        "\n",
        "***Input***: the path to the dataset files _(train, valid, and test)_.\n",
        "\n",
        "\n",
        "```python\n",
        "paths = [\n",
        "    \"dataset/crohme2019_train.txt\",\n",
        "    \"dataset/crohme2019_test.txt\",\n",
        "    \"dataset/crohme2019_valid.txt\",\n",
        "]\n",
        "```\n",
        "\n",
        "***Output***: the vocabulary.\n",
        "\n",
        "```python\n",
        "vocab = {\n",
        "    \"a\": 0,\n",
        "    \"b\": 1,\n",
        "    \"c\": 2,\n",
        "    ...\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "ZGmVmcPDGomI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [\n",
        "    \"dataset/crohme2019_train.txt\",\n",
        "    \"dataset/crohme2019_test.txt\",\n",
        "    \"dataset/crohme2019_valid.txt\",\n",
        "]\n",
        "\n",
        "df = pd.read_csv(paths[1], sep=\"\\t\", header=None, names=[\"path\", \"label\"]).dropna().astype(str)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "vscode": {
          "languageId": "powershell"
        },
        "trusted": true,
        "id": "NVdsl2TqGomI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "964d9b6b-626f-4e94-da28-ad3f6781f834"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        path  \\\n",
              "0     crohme2019/test/UN19_1032_em_455.inkml   \n",
              "1     crohme2019/test/UN19_1044_em_632.inkml   \n",
              "2  crohme2019/test/UN19wb_1111_em_1039.inkml   \n",
              "3     crohme2019/test/UN19_1028_em_394.inkml   \n",
              "4      crohme2019/test/UN19_1005_em_64.inkml   \n",
              "\n",
              "                                               label  \n",
              "0  4 Right n Right - Right 4 Right ) NoRel ( NoRe...  \n",
              "1  \\phi Sub 0 NoRel = Right d Right x Sup 1 Right...  \n",
              "2  9 Right \\times Right 9 Right + Right 1 Right 3...  \n",
              "3  \\tan Right \\alpha Right \\tan Right \\theta Sup ...  \n",
              "4  a Right = NoRel 1 NoRel - Below \\sqrt Inside 2...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6eac05d6-cea4-411a-a3ae-245e9d96f07e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>crohme2019/test/UN19_1032_em_455.inkml</td>\n",
              "      <td>4 Right n Right - Right 4 Right ) NoRel ( NoRe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>crohme2019/test/UN19_1044_em_632.inkml</td>\n",
              "      <td>\\phi Sub 0 NoRel = Right d Right x Sup 1 Right...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>crohme2019/test/UN19wb_1111_em_1039.inkml</td>\n",
              "      <td>9 Right \\times Right 9 Right + Right 1 Right 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>crohme2019/test/UN19_1028_em_394.inkml</td>\n",
              "      <td>\\tan Right \\alpha Right \\tan Right \\theta Sup ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>crohme2019/test/UN19_1005_em_64.inkml</td>\n",
              "      <td>a Right = NoRel 1 NoRel - Below \\sqrt Inside 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6eac05d6-cea4-411a-a3ae-245e9d96f07e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6eac05d6-cea4-411a-a3ae-245e9d96f07e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6eac05d6-cea4-411a-a3ae-245e9d96f07e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-48277aa2-d1e6-434e-8b6e-2e633274e949\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48277aa2-d1e6-434e-8b6e-2e633274e949')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-48277aa2-d1e6-434e-8b6e-2e633274e949 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1198,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1198,\n        \"samples\": [\n          \"crohme2019/test/UN19_1005_em_61.inkml\",\n          \"crohme2019/test/UN19wb_1114_em_1083.inkml\",\n          \"crohme2019/test/UN19wb_1118_em_1142.inkml\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1192,\n        \"samples\": [\n          \"p Right 2 Sup - Right p NoRel - Below 1 Right + Right p NoRel - Right 1 Right ) NoRel (\",\n          \"x Right \\\\rightarrow Right a Right x Right + Right b\",\n          \"\\\\sin Sup 2 NoRel \\\\theta Right \\\\leq Right 1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_chars(paths) -> set:\n",
        "    res = set()\n",
        "    for i in df['label'].apply(lambda x: x.strip().split()):\n",
        "        res.update(i)\n",
        "    return res\n",
        "\n",
        "len(get_unique_chars(paths[0]))"
      ],
      "metadata": {
        "trusted": true,
        "id": "W5WhCEyuGomI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175742e1-4acf-4c0a-bafb-39cae2882b27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = get_unique_chars(paths[0])\n",
        "unique_chars"
      ],
      "metadata": {
        "trusted": true,
        "id": "AODbcsNyGomI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04c8157f-64a0-4afb-b112-cd924d71d1df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!',\n",
              " '(',\n",
              " ')',\n",
              " '+',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " '=',\n",
              " 'A',\n",
              " 'Above',\n",
              " 'B',\n",
              " 'Below',\n",
              " 'C',\n",
              " 'COMMA',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'Inside',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'NoRel',\n",
              " 'P',\n",
              " 'R',\n",
              " 'Right',\n",
              " 'S',\n",
              " 'Sub',\n",
              " 'Sup',\n",
              " 'T',\n",
              " 'V',\n",
              " 'X',\n",
              " 'Y',\n",
              " '[',\n",
              " '\\\\Delta',\n",
              " '\\\\alpha',\n",
              " '\\\\beta',\n",
              " '\\\\cos',\n",
              " '\\\\div',\n",
              " '\\\\exists',\n",
              " '\\\\forall',\n",
              " '\\\\gamma',\n",
              " '\\\\geq',\n",
              " '\\\\gt',\n",
              " '\\\\in',\n",
              " '\\\\infty',\n",
              " '\\\\int',\n",
              " '\\\\lambda',\n",
              " '\\\\ldots',\n",
              " '\\\\leq',\n",
              " '\\\\lim',\n",
              " '\\\\log',\n",
              " '\\\\lt',\n",
              " '\\\\mu',\n",
              " '\\\\neq',\n",
              " '\\\\phi',\n",
              " '\\\\pi',\n",
              " '\\\\pm',\n",
              " '\\\\prime',\n",
              " '\\\\rightarrow',\n",
              " '\\\\sigma',\n",
              " '\\\\sin',\n",
              " '\\\\sqrt',\n",
              " '\\\\sum',\n",
              " '\\\\tan',\n",
              " '\\\\theta',\n",
              " '\\\\times',\n",
              " '\\\\{',\n",
              " '\\\\}',\n",
              " ']',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '|'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vocabulary should be sorted by ascii table. The first character (index 0) must be blank (`''`)."
      ],
      "metadata": {
        "id": "9NoRw8ZUGomI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chr2idx(unique_chars: set) -> dict:\n",
        "    unique_chars.add('')\n",
        "    return {char: idx for idx, char in enumerate(sorted(unique_chars))}\n",
        "\n",
        "vocab = chr2idx(get_unique_chars(paths[0]))\n",
        "\n",
        "assert vocab[\"\"] == 0\n",
        "assert vocab[\"|\"] == 108\n",
        "assert vocab[\"\\\\pi\"] == 68\n",
        "assert vocab[\"\\\\exists\"] == 51\n",
        "assert len(vocab) == 109"
      ],
      "metadata": {
        "trusted": true,
        "id": "MSVwOtmpGomI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    \"\"\"\n",
        "\n",
        "    Attributes:\n",
        "        paths (list): A list of file paths to the annotation files.\n",
        "        char2idx (dict): A dictionary mapping characters to their corresponding indices.  This is the primary vocabulary.\n",
        "        idx2char (dict): A reverse mapping from indices to characters, facilitating decoding.\n",
        "\n",
        "    Methods:\n",
        "        build_vocab(): Builds the vocabulary from the specified annotation files, sorting characters lexicographically and adding a blank character.\n",
        "        get_vocab(): Returns the character-to-index vocabulary.\n",
        "        save_vocab(path): Saves the vocabulary to a JSON file.\n",
        "        encode(tokens): Converts a list of tokens (characters) into a list of their corresponding indices.\n",
        "        decode(ids): Converts a list of indices back into a list of tokens (characters).\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_file=None):\n",
        "        self.char2idx = {}\n",
        "        if vocab_file is not None:\n",
        "            self.char2idx = json.load(open(vocab_file))\n",
        "        self.idx2char = {v: k for k, v in self.char2idx.items()}\n",
        "\n",
        "    def build_vocab(self, annotations) -> None:\n",
        "        vocab = {}\n",
        "        unique_tokens = set()\n",
        "\n",
        "        for anno_files in annotations:\n",
        "            with open(anno_files, 'r', encoding='utf-8') as file:\n",
        "                for each_line in file:\n",
        "                    splitted_line = each_line.strip().split('\\t'); # Split the line into two parts the path and the label (sequence of nodes)\n",
        "                    if len(splitted_line) >= 2:\n",
        "                        sequence = splitted_line[1].strip() # Extract the sequence and split it into individual tokens\n",
        "                        tokens =  sequence.split()\n",
        "                        for token in tokens:\n",
        "                            unique_tokens.add(token)\n",
        "\n",
        "        sorted_tokens = sorted(list(unique_tokens))\n",
        "        vocab = {'': 0}  # Set the blank/ empty string to 0\n",
        "\n",
        "        # Assign each token to indices starting from 1\n",
        "        for idx, char in enumerate(sorted_tokens, start=1):\n",
        "            vocab[char] = idx\n",
        "\n",
        "        # Assign vocab to the class\n",
        "        self.char2idx = vocab\n",
        "\n",
        "    def get_vocab(self) -> dict:  # getter\n",
        "        return self.char2idx\n",
        "\n",
        "    def save_vocab(self, path: str) -> None:  # save vocab to json file\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(self.char2idx, f)\n",
        "\n",
        "    def encode(self, tokens):\n",
        "        return [self.char2idx[token] for token in tokens]\n",
        "\n",
        "    def decode(self, ids):\n",
        "        return [self.idx2char[id] for id in ids]\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "omyRuj9FGomJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECKPOINT: build vocab from annotations\n",
        "annotations = [\n",
        "    \"dataset/crohme2019_train.txt\",\n",
        "    \"dataset/crohme2019_test.txt\",\n",
        "    \"dataset/crohme2019_valid.txt\",\n",
        "]\n",
        "\n",
        "vocab = Vocab()\n",
        "vocab.build_vocab(annotations)\n",
        "vocab.save_vocab('vocab.json')"
      ],
      "metadata": {
        "trusted": true,
        "id": "_LyrowJQGomJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST: vocab class loaded from prebuilt JSON\n",
        "vocab = Vocab('vocab.json')\n",
        "\n",
        "# encoding a sequence\n",
        "input = '- Right \\\\sqrt Inside 2'.split()\n",
        "\n",
        "assert vocab.encode(input) == [5, 37, 74, 30, 10]\n",
        "assert vocab.decode(vocab.encode(input)) == input"
      ],
      "metadata": {
        "trusted": true,
        "id": "2TIxQUHWGomJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Build Dataset\n",
        "\n",
        "In this task, we will build a dataset class that will be used to load the dataset files _(train, valid, and test)_.\n",
        "\n",
        "The dataset class will also be used to preprocess the data by converting the characters in the data to integers using the vocabulary.\n",
        "\n",
        "> _Before going to this task, it is **highly recommended** to read this [Tutorial on creating Custom Dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files) with PyTorch._\n",
        ">\n",
        "> _You should have basic understanding of required methods in the Dataset class such as `__init__`, `__len__`, and `__getitem__`._\n",
        "\n",
        "\n",
        "***Input***: Dataset class should take the following arguments:.\n",
        "\n",
        "- `annotation`: the path to the dataset annotation *(`.txt`)*.\n",
        "- `root_dir`: the root directory of the dataset file.\n",
        "- `vocab`: the vocabulary.\n",
        "\n",
        "***Output***: the dataset class.\n",
        "\n",
        "> *Note: You can adjust the Dataset class base on your references.*\n"
      ],
      "metadata": {
        "id": "Uw6QUu6EGomJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataflow\n",
        "Below is a typical dataflow to train a model.\n",
        "```mermaid\n",
        "flowchart LR\n",
        "    A[Raw Data] --> |parse| B[Cleaned Data]\n",
        "    B --> |feature engineering| C[Dataset]\n",
        "    C --> |package| D[DataLoader]\n",
        "    D --> |load| E[Model]\n",
        "    E --> |predict| F[Output]\n",
        "    F --> |calculate| G[Loss]\n",
        "    G --> |backpropagate| E\n",
        "```"
      ],
      "metadata": {
        "id": "PomjANK6GomJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Inkml files\n",
        "\n",
        "We have an inkml file: `crohme2019/test/UN19_1041_em_597.inkml`\n",
        "\n",
        "Its label is `- Right \\sqrt Inside 2`\n",
        "\n",
        "Target would be: `[5, 37, 74, 30, 10]`, where the index here is the index of tokens (from a vocabulary)\n",
        "\n",
        "We provided you with class `Inkml` to handle the parsing and processing of the inkml files. The main method you will use is `getTraces()` which returns the traces of the inkml file.\n",
        "\n",
        "> _Inspect this class and understand how you should be working with this type of data._\n",
        "\n",
        "```python"
      ],
      "metadata": {
        "id": "r9zozRQ8GomJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Segment(object):\n",
        "    \"\"\"Class to reprsent a Segment compound of strokes (id) with an id and label.\"\"\"\n",
        "\n",
        "    __slots__ = (\"id\", \"label\", \"strId\")\n",
        "\n",
        "    def __init__(self, *args):\n",
        "        if len(args) == 3:\n",
        "            self.id = args[0]\n",
        "            self.label = args[1]\n",
        "            self.strId = args[2]\n",
        "        else:\n",
        "            self.id = \"none\"\n",
        "            self.label = \"\"\n",
        "            self.strId = set([])\n",
        "\n",
        "\n",
        "class Inkml(object):\n",
        "    \"\"\"Class to represent an INKML file with strokes, segmentation and labels\"\"\"\n",
        "\n",
        "    __slots__ = (\"fileName\", \"strokes\", \"strkOrder\", \"segments\", \"truth\", \"UI\")\n",
        "\n",
        "    NS = {\n",
        "        \"ns\": \"http://www.w3.org/2003/InkML\",\n",
        "        \"xml\": \"http://www.w3.org/XML/1998/namespace\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, *args):\n",
        "        self.fileName = None\n",
        "        self.strokes = {}\n",
        "        self.strkOrder = []\n",
        "        self.segments = {}\n",
        "        self.truth = \"\"\n",
        "        self.UI = \"\"\n",
        "        if len(args) == 1:\n",
        "            self.fileName = args[0]\n",
        "            self.loadFromFile()\n",
        "\n",
        "    def fixNS(self, ns, att):\n",
        "        \"\"\"Build the right tag or element name with namespace\"\"\"\n",
        "        return \"{\" + Inkml.NS[ns] + \"}\" + att\n",
        "\n",
        "    def loadFromFile(self):\n",
        "        \"\"\"load the ink from an inkml file (strokes, segments, labels)\"\"\"\n",
        "        tree = ET.parse(self.fileName)\n",
        "        # # ET.register_namespace();\n",
        "        root = tree.getroot()\n",
        "        for info in root.findall(\"ns:annotation\", namespaces=Inkml.NS):\n",
        "            if \"type\" in info.attrib:\n",
        "                if info.attrib[\"type\"] == \"truth\":\n",
        "                    self.truth = info.text.strip()\n",
        "                if info.attrib[\"type\"] == \"UI\":\n",
        "                    self.UI = info.text.strip()\n",
        "        for strk in root.findall(\"ns:trace\", namespaces=Inkml.NS):\n",
        "            self.strokes[strk.attrib[\"id\"]] = strk.text.strip()\n",
        "            self.strkOrder.append(strk.attrib[\"id\"])\n",
        "        segments = root.find(\"ns:traceGroup\", namespaces=Inkml.NS)\n",
        "        if segments is None or len(segments) == 0:\n",
        "            return\n",
        "        for seg in segments.iterfind(\"ns:traceGroup\", namespaces=Inkml.NS):\n",
        "            id = seg.attrib[self.fixNS(\"xml\", \"id\")]\n",
        "            label = seg.find(\"ns:annotation\", namespaces=Inkml.NS).text\n",
        "            strkList = set([])\n",
        "            for t in seg.findall(\"ns:traceView\", namespaces=Inkml.NS):\n",
        "                strkList.add(t.attrib[\"traceDataRef\"])\n",
        "            self.segments[id] = Segment(id, label, strkList)\n",
        "\n",
        "    def getTraces(self, height=256):\n",
        "        traces_array = [\n",
        "            np.array(\n",
        "                [p.strip().split() for p in self.strokes[id].split(\",\")], dtype=\"float\"\n",
        "            )\n",
        "            for id in self.strkOrder\n",
        "        ]\n",
        "\n",
        "        ratio = height / (\n",
        "            (\n",
        "                np.concatenate(traces_array, 0).max(0)\n",
        "                - np.concatenate(traces_array, 0).min(0)\n",
        "            )[1]\n",
        "            + 1e-6\n",
        "        )\n",
        "        return [(trace * ratio).astype(int).tolist() for trace in traces_array]\n",
        "\n",
        "    def view(self):\n",
        "        plt.figure(figsize = (16, 4))\n",
        "        plt.axis(\"off\")\n",
        "        for trace in self.getTraces():\n",
        "            trace_arr = np.array(trace)\n",
        "            plt.plot(trace_arr[:, 0], -trace_arr[:, 1])  # invert y coordinate"
      ],
      "metadata": {
        "trusted": true,
        "id": "hkOSwWi0GomJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "inkml_path = '/content/dataset/crohme2019/crohme2019/test/ISICal19_1202_em_771.inkml'\n",
        "ink = Inkml(inkml_path)\n",
        "ink.view()"
      ],
      "metadata": {
        "trusted": true,
        "id": "c3ofnZJ7GomJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "6221ee84-a0c1-4688-875a-7c78542e4df4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Display shapes of first 5 traces in one file\n",
        "\n",
        "[np.array(trace).shape for trace in ink.getTraces()][:20]"
      ],
      "metadata": {
        "trusted": true,
        "id": "_EsBxMv1GomJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595ac763-07ab-40ef-ac57-4196e74ff879"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(46, 2),\n",
              " (32, 2),\n",
              " (22, 2),\n",
              " (39, 2),\n",
              " (17, 2),\n",
              " (47, 2),\n",
              " (24, 2),\n",
              " (39, 2),\n",
              " (18, 2),\n",
              " (32, 2),\n",
              " (14, 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **REMARK**: _Some Inkml may return (x, y, t) coordinates, while most of them return (x, y) coordinates. Make sure to handle this inconsistency in your implementation._"
      ],
      "metadata": {
        "id": "52ybjkd4GomJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Dataset\n",
        "\n",
        "For calculating the Connectionist Temporal Classification (CTC) loss, read the [expected output](https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html) of this loss function from PyTorch.\n",
        "\n",
        "> _Hint: focus on the shapes and the expected variables. (see code example for calculating loss)_\n",
        "> ```python\n",
        "> loss = ctc_loss(input_tensor, target_tensor, input_lengths, target_lengths)\n",
        "> ```\n",
        "\n",
        "**Base on the observation, how can we build a dataset class from the dataset files?**\n",
        "\n",
        "> Hints:\n",
        ">   - *Understand the big picture. (Dataflow)*\n",
        ">   - *What informations needed to calculate our Loss?*\n",
        ">   - *What should be returned in the `__getitem__` method?*\n",
        ">   - *The outputs should be of Tensor type*\n",
        "   \n",
        "***References from pytorch [tutorials](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)***\n",
        "\n",
        "`torch.utils.data.Dataset` is an abstract class representing a dataset. Your custom dataset should inherit `Dataset` and override the following methods:\n",
        "\n",
        "- `__len__` so that `len(dataset)` returns the size of the dataset.\n",
        "\n",
        "- `__getitem__` to support the indexing such that `dataset[i]` can be used to get ith sample.\n"
      ],
      "metadata": {
        "id": "G9dQJ7TTGomJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature representation\n",
        "\n",
        "In this task, we will convert the strokes into feature representations that can be used by the model.\n",
        "\n",
        "Initially, the `.getTraces()` method returns list of strokes, where each stroke is a list of (x, y) coordinates. Intuitively, we can use those coordinates as features. But if directly using the coordinates as features, the model will have a hard time learning the patterns.\n",
        "\n",
        "Instead, we can calculate the difference *(∆d)* between consecutive coordinates as features. This way, the model can learn the patterns more easily.\n",
        "\n",
        "$\\Delta_x = x_{i+1} - x_i$ and $\\Delta_y = y_{i+1} - y_i$\n",
        "\n",
        "The feature would then be normalized as\n",
        "\n",
        "($\\frac{\\Delta_x}{d}$ , $\\frac{\\Delta_y} {d}$), where $d = \\sqrt{\\Delta_x^2 + \\Delta_y^2}$\n",
        "\n",
        "**Pen-up and Pen-down**\n",
        "\n",
        "In the dataset, each stroke is separated by a pen-up event. We can use this information to separate the strokes.\n",
        "\n",
        "1. The pen is lifted from the paper (connecting the end of a stroke to the start of a stroke): $pen\\_up = 1$\n",
        "2. The pen is on the paper: $pen\\_up = 0$\n",
        "\n",
        "Then, our feature representation would be:\n",
        "($\\frac{\\Delta_x}{d}$ , $\\frac{\\Delta_y} {d}$, $d$, $pen\\_up$)\n",
        "\n",
        "\n",
        "```\n",
        "point 1: (x1, y1)\n",
        "point 2: (x2, y2)\n",
        "point 3: (x3, y3) <--- end of stroke #1\n",
        "point 4: (x4, y4) <--- start of stroke #2\n",
        "...\n",
        "point n: (xn, yn)\n",
        "```\n",
        "\n",
        "The feature representation will be:\n",
        "\n",
        "```\n",
        "f1 = ((x2 - x1) / d, (y2 - y1)/d, d, 0)\n",
        "f2 = ((x3 - x2) / d, (y3 - y2)/d, d, 0)\n",
        "f3 = ((x4 - x3) / d, (y4 - y3)/d, d, 1) <-- pen up\n",
        "...\n",
        "fn-1 = ((xn - xn-1) / d, (yn - yn-1)/d, d, 0)\n",
        "```"
      ],
      "metadata": {
        "id": "3ugfZokVGomK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **CHECK LIST**\n",
        "\n",
        "For each data sample, we will do the following steps\n",
        "- Combine all the strokes into a single stroke (N, 2)\n",
        "- Compute first order differences of x and y coordinates\n",
        "- Remove any zero length strokes\n",
        "- Compute Euclidean distances between consecutive points\n",
        "- Normalize the x and y coordinates by Euclidean distance\n",
        "- Add feature pen-up/pen-down\n",
        "> *Features of transformed data: (delta traces, distance, pen_up_down)*\n",
        "\n",
        "Label\n",
        "- Define label (list of indices of the words)\n",
        "\n",
        "Finally, we will convert the data and label to PyTorch tensors.\n",
        "- Convert data and label to PyTorch tensors"
      ],
      "metadata": {
        "id": "_LJH9zHvGomK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InkmlDataset(Dataset):\n",
        "    def __init__(self, annotation, root_dir, vocab):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            annotation (string): annotation file txt.\n",
        "            root_dir (string): directory holds the dataset.\n",
        "            vocab (set): of vocab.\n",
        "        \"\"\"\n",
        "        self.annotation = annotation\n",
        "        self.root_dir = root_dir\n",
        "        self.vocab = vocab\n",
        "\n",
        "        # load annotations\n",
        "        self.inks = []\n",
        "        self.labels = []\n",
        "        # Parse annotation file\n",
        "        self._load_annotations()\n",
        "\n",
        "    def _load_annotations(self):\n",
        "        \"\"\"Load and parse annotation file\"\"\"\n",
        "        try:\n",
        "            with open(self.annotation, 'r', encoding='utf-8') as file:\n",
        "                lines = file.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if not line:  # Skip empty lines\n",
        "                    continue\n",
        "\n",
        "                parts = line.split('\\t', 1)  # Split only on first tab\n",
        "                if len(parts) == 2:\n",
        "                    relative_path, label_text = parts\n",
        "                    full_path = os.path.join(self.root_dir, relative_path.strip())\n",
        "                    self.inks.append(full_path)\n",
        "                    self.labels.append(label_text.strip())\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            raise FileNotFoundError(f\"Annotation file not found: {self.annotation}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of samples in the dataset\"\"\"\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Return the idx-th sample in the dataset\"\"\"\n",
        "\n",
        "        # Get paths and labels\n",
        "        ink_file_path = self.inks[idx]\n",
        "        target_label = self.labels[idx]\n",
        "\n",
        "        # Load inkml file\n",
        "        inkml_obj = Inkml(ink_file_path)\n",
        "        stroke_list = inkml_obj.getTraces()\n",
        "\n",
        "\n",
        "        feature_sequence = self._extract_features(stroke_list)\n",
        "\n",
        "        # Convert to tensors\n",
        "        input_tensor = torch.tensor(feature_sequence, dtype=torch.float32)\n",
        "        input_length = torch.tensor(len(feature_sequence), dtype=torch.long)\n",
        "\n",
        "        # Process labels\n",
        "        target_tokens = target_label.split()\n",
        "        encoded_targets = self.vocab.encode(target_tokens)\n",
        "        target_tensor = torch.tensor(encoded_targets, dtype=torch.long)\n",
        "        target_length = torch.tensor(len(encoded_targets), dtype=torch.long)\n",
        "\n",
        "        return input_tensor, target_tensor, input_length, target_length\n",
        "\n",
        "    def _extract_features(self, strokes):\n",
        "        all_features = []\n",
        "        previous_point = None\n",
        "        current_stroke_idx = -1\n",
        "\n",
        "        for stroke_number, current_stroke in enumerate(strokes):\n",
        "            for point in current_stroke:\n",
        "                # Handle both (x,y) and (x,y,t)\n",
        "                if len(point) >= 2:\n",
        "                    x_coord, y_coord = float(point[0]), float(point[1])\n",
        "                else:\n",
        "                    continue  # skip other points\n",
        "\n",
        "                if previous_point is None:\n",
        "                    previous_point = (x_coord, y_coord)\n",
        "                    current_stroke_idx = stroke_number\n",
        "                    continue\n",
        "\n",
        "                d_x = x_coord - previous_point[0]\n",
        "                d_y = y_coord - previous_point[1]\n",
        "                euclidean_dist = (d_x**2 + d_y**2)**0.5\n",
        "\n",
        "                # Skip if no movement\n",
        "                if euclidean_dist < 1e-6: # small epsilon instead of 0\n",
        "                    continue\n",
        "\n",
        "                #normalize\n",
        "                normalized_dx = d_x / euclidean_dist\n",
        "                normalized_dy = d_y / euclidean_dist\n",
        "\n",
        "                is_pen_up = 1 if stroke_number > current_stroke_idx else 0\n",
        "\n",
        "                #feature vector\n",
        "                feature_vector = [normalized_dx, normalized_dy, euclidean_dist, is_pen_up]\n",
        "                all_features.append(feature_vector)\n",
        "\n",
        "                # Update state\n",
        "                previous_point = (x_coord, y_coord)\n",
        "                current_stroke_idx = stroke_number\n",
        "\n",
        "        return all_features"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lyx5HT98GomK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Build Lightning Data Module via Dataloader\n",
        "\n",
        "Revise [this tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders) to see how you can prepare your data for training with DataLoader.\n",
        "\n",
        "Then refer to this [documentation](https://pytorch.org/docs/stable/data.html#loading-batched-and-non-batched-data) to understand how DataLoader in PyTorch loads Batched or Non-Batched data.\n",
        "\n",
        "> **TASK:** Write the dataloader with custom collate function to pad the input and target sequence\n",
        "\n",
        "For a better understanding of the importance of handling variable-length sequences in deep learning models, it is crucial to format and pad the data appropriately to ensure consistency during training. Learn more about this topic [here](https://plainenglish.io/blog/understanding-collate-fn-in-pytorch-f9d1742647d3).\n",
        "\n",
        "> _**Hint 1**: use `torch.nn.utils.rnn.pad_sequence` to pad the input and target sequences. Read more about this function [here](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html)._\n",
        "\n",
        "> _**Hint 2**: read Example 3 from this [tutorial](https://www.programiz.com/python-programming/methods/built-in/zip) to unpack data using `zip()`._"
      ],
      "metadata": {
        "id": "O3GGK6yRGomK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"Create batch\"\"\"\n",
        "    input_tensors, target_tensors, input_lengths, target_lengths = zip(*batch)\n",
        "    features = pad_sequence(input_tensors, batch_first=True, padding_value=0.0)\n",
        "\n",
        "    # Pad\n",
        "    labels = pad_sequence(target_tensors, batch_first=True, padding_value=0)\n",
        "\n",
        "    input_lens = torch.stack(input_lengths)\n",
        "    label_lens = torch.stack(target_lengths)\n",
        "\n",
        "    return features, labels, input_lens, label_lens"
      ],
      "metadata": {
        "trusted": true,
        "id": "MsUUX0j0GomK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Vocab('vocab.json')\n",
        "dataset = InkmlDataset(annotation=\"dataset/crohme2019_test.txt\", root_dir=\"dataset/crohme2019\", vocab=vocab)\n",
        "features, labels, input_lens, label_lens = collate_fn([dataset[0], dataset[1]])\n",
        "\n",
        "import numpy.testing as npt\n",
        "\n",
        "assert type(input_lens) == torch.Tensor\n",
        "assert type(label_lens) == torch.Tensor\n",
        "assert type(features) == torch.Tensor\n",
        "assert type(labels) == torch.Tensor\n",
        "\n",
        "# print(f\"Features shape: {features.shape}\")\n",
        "# print(f\"Labels shape: {labels.shape}\")\n",
        "# print(f\"Input lengths: {input_lens}\")\n",
        "# print(f\"Label lengths: {label_lens}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "Z-eUDB9mGomK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **TASK:** implement InkmlDataset_PL Lightning Datamodule"
      ],
      "metadata": {
        "id": "HqdtEV0FGomK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InkmlDataset_PL(pl.LightningDataModule):\n",
        "    \"\"\"\n",
        "    PyTorch Lightning data module for handling the INKML dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        batch_size: int = 10,\n",
        "        num_workers: int = 4,\n",
        "        train_annotation: str = \"\",\n",
        "        validation_annotation: str = \"\",\n",
        "        test_annotation: str = \"\",\n",
        "        root_dir: str = \"dataset\",\n",
        "        vocab_file: str = \"vocab.json\"\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.train_annotation = train_annotation\n",
        "        self.val_annotation = validation_annotation\n",
        "        self.test_annotation = test_annotation\n",
        "        self.root_dir = root_dir\n",
        "        self.vocab_file = vocab_file\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Load vocabulary\n",
        "        vocab = Vocab(self.vocab_file)\n",
        "\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            self.train_dataset = InkmlDataset(\n",
        "                self.train_annotation,\n",
        "                root_dir=self.root_dir,\n",
        "                vocab=vocab\n",
        "            )\n",
        "            self.val_dataset = InkmlDataset(\n",
        "                self.val_annotation,\n",
        "                root_dir=self.root_dir,\n",
        "                vocab=vocab\n",
        "            )\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.test_dataset = InkmlDataset(\n",
        "                self.test_annotation,\n",
        "                root_dir=self.root_dir,\n",
        "                vocab=vocab\n",
        "            )\n",
        "\n",
        "    def custom_collate_fn(self, batch):\n",
        "        \"\"\"Custom collate function for variable-length sequences\"\"\"\n",
        "        # Unpack batch\n",
        "        input_tensors, target_tensors, input_lengths, target_lengths = zip(*batch)\n",
        "\n",
        "        # Pad sequences\n",
        "        padded_traces = pad_sequence(input_tensors, batch_first=True, padding_value=0.0)\n",
        "        padded_labels = pad_sequence(target_tensors, batch_first=True, padding_value=0)\n",
        "\n",
        "        # Stack lengths\n",
        "        len_traces = torch.stack(input_lengths)\n",
        "        len_labels = torch.stack(target_lengths)\n",
        "\n",
        "        return padded_traces, padded_labels, len_traces, len_labels\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            collate_fn=self.custom_collate_fn,\n",
        "            shuffle=True  # Added shuffle for training\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            collate_fn=self.custom_collate_fn,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            collate_fn=self.custom_collate_fn,\n",
        "        )"
      ],
      "metadata": {
        "trusted": true,
        "id": "7lVgTU25GomK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Build Model\n",
        "\n",
        "In this task, we will build a model that will be used to train the dataset.\n",
        "The model will be a simple RNN with a single layer of Bidirectional LSTM cells. The model will take the input from the dataset and output the predicted sequence of symbols and relations and will use CTC loss to train the model.\n",
        "\n",
        "The model will be built using PyTorch and will use the following architecture\n"
      ],
      "metadata": {
        "id": "JzRl-DlmGomL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> _We highly recommend you to read through this [tutorial on Creating a model using Pytorch](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html) and understand the basic building blocks of a model in PyTorch._"
      ],
      "metadata": {
        "id": "bb_9WrCkGomL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> _**ATTENTION** Below is the architecture for the model. You must **STRICTLY** follow the architecture and the parameters mentioned below._\n",
        "> | Layer Type         | Configuration                              |\n",
        "> |--------------------|--------------------------------------------|\n",
        "> | Input              | Sequence of vectors with `input_size=4`    |\n",
        "> | LSTM Layer         | `hidden_size=256`, `num_layers=2`          |\n",
        "> |                    | `batch_first=True`                         |\n",
        "> |                    | `bidirectional=True`                       |\n",
        "> | LSTM Output        | Output shape: `(batch_size, seq_len, hidden_size*2)`|\n",
        "> | Fully Connected    | `Linear(hidden_size*2, num_classes)`|\n",
        "> | Activation         | `LogSoftmax(dim=...)`|\n",
        "> | Output             | `(batch_size, seq_len, num_classes)`|\n"
      ],
      "metadata": {
        "id": "9SIq1MeSGomL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_TemporalClassification(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM_TemporalClassification, self).__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size, # 4 features\n",
        "            hidden_size=hidden_size, # 256\n",
        "            num_layers=num_layers, # 2 layers\n",
        "            batch_first=True, # Input shape: (batch, seq, features)\n",
        "            bidirectional=True # Forward + backward = 2*hidden_size output\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        fc_out = self.fc(lstm_out)\n",
        "        output = self.log_softmax(fc_out)\n",
        "        return output"
      ],
      "metadata": {
        "trusted": true,
        "id": "Z24pJPawGomL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your implementation\n",
        "model = LSTM_TemporalClassification(4, 256, 2, 109)\n",
        "assert model.forward(torch.rand((10, 100, 4))).shape == (10, 100, 109)"
      ],
      "metadata": {
        "trusted": true,
        "id": "sBM9L41uGomP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5: Understand CTC Loss\n",
        "\n",
        "In this task, we will understand how to use CTC loss to train the model. The CTC loss is used to train the model to predict the sequence of symbols and relations from the input sequence of features.\n",
        "\n",
        "> _For deeper understanding of CTC loss, read this [blog](https://distill.pub/2017/ctc/)_\n",
        "\n",
        "Check out this [Pytorch documentation](https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html) to learn more about its implementation.\n",
        "\n",
        "> _Hint: read the expected input and output of the CTC loss function. The input should be of shape `(T, N, C)` where T is the length of the input sequence, N is the batch size, and C is the number of classes. The target should be of shape `(N, S)` where S is the length of the target sequence._\n",
        "\n",
        "After understanding how CTC Loss works, we can proceed to implement it in our model."
      ],
      "metadata": {
        "id": "e6V0E9xSGomP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From task 9: This was added to make the run easier\n",
        "class GreedyCTCDecoder(torch.nn.Module):\n",
        "    def __init__(self, vocab):\n",
        "        super().__init__()\n",
        "        self.vocab = vocab\n",
        "        self.blank = vocab.char2idx[\"\"]\n",
        "    def forward(self, emission: torch.Tensor) -> list:\n",
        "\n",
        "        # Get the best path (indices with highest probability at each timestep)\n",
        "        indices = torch.argmax(emission, dim=-1)\n",
        "\n",
        "        # Remove nearby duplicates\n",
        "        collapsed_indices = []\n",
        "        previous_idx = None\n",
        "\n",
        "        for idx in indices:\n",
        "            idx_item = idx.item()\n",
        "            if idx_item != previous_idx:  # only add if different from previous\n",
        "                collapsed_indices.append(idx_item)\n",
        "                previous_idx = idx_item\n",
        "\n",
        "        # Remove blanks\n",
        "        filtered_indices = [idx for idx in collapsed_indices if idx != self.blank]\n",
        "\n",
        "        #Convert indices back to tokens using vocabulary\n",
        "        output_seq_list = self.vocab.decode(filtered_indices)\n",
        "\n",
        "        return output_seq_list"
      ],
      "metadata": {
        "id": "unh-tcM_I6Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From task 10: this was added to make the run easier\n",
        "def edit_distance(predicted_sequence, label_sequence):\n",
        "\n",
        "    len_pred = len(predicted_sequence)\n",
        "    len_label = len(label_sequence)\n",
        "\n",
        "    distance_grid = [[0] * (len_label + 1) for _ in range(len_pred + 1)]\n",
        "    for j in range(len_label + 1):\n",
        "        distance_grid[0][j] = j\n",
        "\n",
        "    for i in range(len_pred + 1):\n",
        "        distance_grid[i][0] = i\n",
        "\n",
        "    for i in range(1, len_pred + 1):\n",
        "        for j in range(1, len_label + 1):\n",
        "            sub_cost = 0 if predicted_sequence[i - 1] == label_sequence[j - 1] else 1\n",
        "            delete_cost = distance_grid[i - 1][j] + 1\n",
        "            insert_cost = distance_grid[i][j - 1] + 1\n",
        "            substitution_path_cost = distance_grid[i - 1][j - 1] + sub_cost\n",
        "\n",
        "            distance_grid[i][j] = min(delete_cost, insert_cost, substitution_path_cost)\n",
        "\n",
        "    return distance_grid[len_pred][len_label]\n"
      ],
      "metadata": {
        "id": "OzlAjtYBJELT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 6: Build Lightning Module\n",
        "\n",
        "In this task, we will build a Lightning module that will be used to train the model. The Lightning module will mostly be used to define the training and validation steps, as well as the optimizer and learning rate scheduler.\n",
        "\n",
        "> _More on building Lightning module can be found [here](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html). You should read about core methods to know what to implement in your module._"
      ],
      "metadata": {
        "id": "qvim4uxsGomP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_tokens(vocab):\n",
        "    \"\"\"Categorize tokens into symbols and relations\"\"\"\n",
        "    relations = {\n",
        "        'Right', 'Left', 'Above', 'Below', 'Sub', 'Sup', 'Inside', 'NoRel'\n",
        "    }\n",
        "\n",
        "    symbols = set()\n",
        "    relation_tokens = set()\n",
        "\n",
        "    for token in vocab.char2idx.keys():\n",
        "        if token == '':  # blank token\n",
        "            continue\n",
        "        elif token in relations:\n",
        "            relation_tokens.add(token)\n",
        "        else:\n",
        "            symbols.add(token)\n",
        "\n",
        "    return symbols, relation_tokens\n",
        "\n",
        "def calculate_separate_wer(predicted_tokens, ground_truth_tokens, vocab):\n",
        "    \"\"\"Calculate WER separately for symbols and relations\"\"\"\n",
        "    symbols, relations = categorize_tokens(vocab)\n",
        "\n",
        "    # Separate predicted tokens\n",
        "    pred_symbols = [token for token in predicted_tokens if token in symbols]\n",
        "    pred_relations = [token for token in predicted_tokens if token in relations]\n",
        "\n",
        "    # Separate ground truth tokens\n",
        "    gt_symbols = [token for token in ground_truth_tokens if token in symbols]\n",
        "    gt_relations = [token for token in ground_truth_tokens if token in relations]\n",
        "\n",
        "    # Calculate edit distances\n",
        "    symbol_edit_dist = edit_distance(pred_symbols, gt_symbols)\n",
        "    relation_edit_dist = edit_distance(pred_relations, gt_relations)\n",
        "\n",
        "    # Calculate WERs\n",
        "    symbol_wer = symbol_edit_dist / len(gt_symbols) if len(gt_symbols) > 0 else 0.0\n",
        "    relation_wer = relation_edit_dist / len(gt_relations) if len(gt_relations) > 0 else 0.0\n",
        "\n",
        "    return symbol_wer, relation_wer"
      ],
      "metadata": {
        "id": "xsaDLjNEYoGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MathOnlineModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        lr=0.001,\n",
        "        input_size=4,\n",
        "        output_size=109,\n",
        "        hidden_size=256,\n",
        "        num_layers=2,\n",
        "        decoder=None,\n",
        "        constraint_weight=0.1,\n",
        "        lr_scheduler_patience=5,\n",
        "        lr_scheduler_factor=0.1,\n",
        "        monitor_metric=\"val_wer\",\n",
        "        use_cuda_decoder=True,  # NEW: Option to use CUDA decoder\n",
        "        beam_size=10  # NEW: Beam size for CUDA decoder\n",
        "    ):\n",
        "        self.save_hyperparameters()\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = LSTM_TemporalClassification(\n",
        "            input_size, hidden_size, num_layers, output_size\n",
        "        )\n",
        "        self.criterion = nn.CTCLoss(\n",
        "            blank=0,\n",
        "            reduction='mean',\n",
        "            zero_infinity=True\n",
        "        )\n",
        "        self.lr = lr\n",
        "        self.constraint_weight = constraint_weight\n",
        "\n",
        "        # Initialize decoder\n",
        "        if decoder is None:\n",
        "            vocab = Vocab('vocab.json')\n",
        "            if use_cuda_decoder:\n",
        "                self.decoder = CUDACTCDecoder(vocab, beam_size=beam_size)\n",
        "                print(\"✓ Using CUDA CTC Decoder\")\n",
        "            else:\n",
        "                self.decoder = GreedyCTCDecoder(vocab)\n",
        "                print(\"✓ Using Greedy CTC Decoder\")\n",
        "        else:\n",
        "            self.decoder = decoder\n",
        "\n",
        "        self.relation_indices = self._get_relation_indices()\n",
        "        self.lr_scheduler_patience = lr_scheduler_patience\n",
        "        self.lr_scheduler_factor = lr_scheduler_factor\n",
        "        self.monitor_metric = monitor_metric\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    def _get_relation_indices(self):\n",
        "        \"\"\"Get indices of relation tokens in vocabulary\"\"\"\n",
        "        relations = {'Right', 'Left', 'Above', 'Below', 'Sub', 'Sup', 'Inside', 'NoRel'}\n",
        "        vocab = self.decoder.vocab\n",
        "        relation_indices = []\n",
        "\n",
        "        for token, idx in vocab.char2idx.items():\n",
        "            if token in relations:\n",
        "                relation_indices.append(idx)\n",
        "\n",
        "        return torch.tensor(relation_indices, dtype=torch.long)\n",
        "    def _calculate_constraint_loss(self, log_probs, input_features, input_lengths):\n",
        "        batch_size, seq_len, num_classes = log_probs.shape\n",
        "        device = log_probs.device\n",
        "\n",
        "        # Move relation indices to correct device\n",
        "        relation_indices = self.relation_indices.to(device)\n",
        "        total_constraint_loss = 0.0\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            try:\n",
        "                actual_len = input_lengths[i].item()\n",
        "\n",
        "                if actual_len <= 0 or actual_len > seq_len:\n",
        "                    continue\n",
        "\n",
        "                pen_up_states = input_features[i, :actual_len, 3]\n",
        "                pen_down_mask = (pen_up_states == 0).float()\n",
        "\n",
        "                # Check for NaN in input features\n",
        "                if torch.isnan(pen_down_mask).any():\n",
        "                    print(f\"NaN detected in pen_down_mask for batch {i}\")\n",
        "                    continue\n",
        "\n",
        "                log_probs_sample = log_probs[i, :actual_len, :]\n",
        "\n",
        "                if torch.isnan(log_probs_sample).any():\n",
        "                    print(f\"NaN detected in log_probs for batch {i}\")\n",
        "                    continue\n",
        "\n",
        "                log_probs_clamped = torch.clamp(log_probs_sample, min=-50, max=50)\n",
        "                probs = torch.exp(log_probs_clamped)\n",
        "\n",
        "                # Get relation probabilities\n",
        "                if len(relation_indices) > 0:\n",
        "                    relation_probs = probs[:, relation_indices]\n",
        "                    p_rel = torch.sum(relation_probs, dim=1)\n",
        "                else:\n",
        "                    p_rel = torch.zeros(actual_len, device=device)\n",
        "\n",
        "                constraint_term = torch.sum(p_rel * pen_down_mask)\n",
        "\n",
        "                # Clamp\n",
        "                constraint_term = torch.clamp(constraint_term, min=0.0, max=actual_len)\n",
        "\n",
        "                # Add epsilon and clamp the argument to log\n",
        "                eps = 1e-8\n",
        "                log_arg = torch.clamp(1.0 - constraint_term + eps, min=eps, max=1.0)\n",
        "                constraint_loss = -torch.log(log_arg)\n",
        "\n",
        "                # Final NaN check\n",
        "                if torch.isnan(constraint_loss) or torch.isinf(constraint_loss):\n",
        "                    print(f\"Invalid constraint_loss for batch {i}: {constraint_loss}\")\n",
        "                    constraint_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "                total_constraint_loss += constraint_loss\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in constraint loss calculation for batch {i}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Return safe constraint loss\n",
        "        if batch_size > 0:\n",
        "            final_loss = total_constraint_loss / batch_size\n",
        "        else:\n",
        "            final_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "        return final_loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y, x_lens, y_lens = batch\n",
        "        log_probs = self.forward(x)\n",
        "        log_probs_ctc = log_probs.transpose(0, 1)  # (seq_len, batch_size, num_classes)\n",
        "\n",
        "        ctc_loss = self.criterion(\n",
        "            log_probs=log_probs_ctc,\n",
        "            targets=y,\n",
        "            input_lengths=x_lens,\n",
        "            target_lengths=y_lens\n",
        "        )\n",
        "        constraint_loss = self._calculate_constraint_loss(log_probs, x, x_lens)\n",
        "        total_loss = ctc_loss + self.constraint_weight * constraint_loss\n",
        "        wer, wer_sym, wer_rel = self._calculate_wer(log_probs, y, x_lens, y_lens)\n",
        "\n",
        "        # Log learning rate\n",
        "        lr = self.optimizers().param_groups[0]['lr']\n",
        "        self.log('learning_rate', lr, on_step=True, on_epoch=False, prog_bar=False)\n",
        "\n",
        "        self.log(\"train_loss\", total_loss, prog_bar=True, on_step=True, on_epoch=True)\n",
        "        self.log(\"train_ctc_loss\", ctc_loss, prog_bar=False, on_step=True, on_epoch=True)\n",
        "        self.log(\"train_constraint_loss\", constraint_loss, prog_bar=False, on_step=True, on_epoch=True)\n",
        "        self.log(\"train_wer\", wer, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"train_wer_sym\", wer_sym, prog_bar=False, on_step=False, on_epoch=True)\n",
        "        self.log(\"train_wer_rel\", wer_rel, prog_bar=False, on_step=False, on_epoch=True)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, x_lens, y_lens = batch\n",
        "        log_probs = self.forward(x)\n",
        "        log_probs_ctc = log_probs.transpose(0, 1)\n",
        "        ctc_loss = self.criterion(\n",
        "            log_probs=log_probs_ctc,\n",
        "            targets=y,\n",
        "            input_lengths=x_lens,\n",
        "            target_lengths=y_lens\n",
        "        )\n",
        "\n",
        "\n",
        "        constraint_loss = self._calculate_constraint_loss(log_probs, x, x_lens)\n",
        "        total_loss = ctc_loss + self.constraint_weight * constraint_loss\n",
        "        wer, wer_sym, wer_rel = self._calculate_wer(log_probs, y, x_lens, y_lens)\n",
        "\n",
        "        # Log metrics\n",
        "        self.log(\"val_loss\", total_loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"val_ctc_loss\", ctc_loss, prog_bar=False, on_step=False, on_epoch=True)\n",
        "        self.log(\"val_constraint_loss\", constraint_loss, prog_bar=False, on_step=False, on_epoch=True)\n",
        "        self.log(\"val_wer\", wer, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"val_wer_sym\", wer_sym, prog_bar=False, on_step=False, on_epoch=True)\n",
        "        self.log(\"val_wer_rel\", wer_rel, prog_bar=False, on_step=False, on_epoch=True)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y, x_lens, y_lens = batch\n",
        "\n",
        "        # Forward pass\n",
        "        log_probs = self.forward(x) # Shape: (batch=16, seq_len, 109)\n",
        "\n",
        "        # Create separate variable for CTC loss\n",
        "        log_probs_ctc = log_probs.transpose(0, 1) # Shape: (seq_len, batch=16, 109)\n",
        "\n",
        "        # CTC Loss calculation\n",
        "        loss = self.criterion(\n",
        "            log_probs=log_probs_ctc,\n",
        "            targets=y,\n",
        "            input_lengths=x_lens,\n",
        "            target_lengths=y_lens\n",
        "        )\n",
        "\n",
        "        # WER calculation\n",
        "        wer, wer_sym, wer_rel = self._calculate_wer(log_probs, y, x_lens, y_lens)\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"test_wer\", wer, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(\"test_wer_sym\", wer_sym, prog_bar=False, on_step=False, on_epoch=True)\n",
        "        self.log(\"test_wer_rel\", wer_rel, prog_bar=False, on_step=False, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def _calculate_wer(self, log_probs, targets, input_lengths, target_lengths):\n",
        "        batch_size = log_probs.size(0)\n",
        "        total_edit_distance = 0\n",
        "        total_target_length = 0\n",
        "        total_symbol_edit_distance = 0\n",
        "        total_symbol_length = 0\n",
        "        total_relation_edit_distance = 0\n",
        "        total_relation_length = 0\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            # Get predictions for this sample\n",
        "            sample_log_probs = log_probs[i, :input_lengths[i], :]\n",
        "\n",
        "            # Decode predictions\n",
        "            try:\n",
        "                predicted_tokens = self.decoder.forward(sample_log_probs)\n",
        "            except Exception:\n",
        "                predicted_tokens = []\n",
        "\n",
        "            # Get ground truth tokens\n",
        "            target_tokens = targets[i, :target_lengths[i]].tolist()\n",
        "\n",
        "            # Convert target indices to tokens using vocab\n",
        "            try:\n",
        "                vocab = self.decoder.vocab\n",
        "                ground_truth_tokens = vocab.decode(target_tokens)\n",
        "            except Exception:\n",
        "                ground_truth_tokens = []\n",
        "\n",
        "            # Calculate overall edit distance\n",
        "            edit_dist = edit_distance(predicted_tokens, ground_truth_tokens)\n",
        "            total_edit_distance += edit_dist\n",
        "            total_target_length += len(ground_truth_tokens)\n",
        "\n",
        "            # Calculate separate WERs\n",
        "            symbol_wer, relation_wer = calculate_separate_wer(\n",
        "                predicted_tokens, ground_truth_tokens, vocab\n",
        "            )\n",
        "\n",
        "            # Track separate metrics\n",
        "            symbols, relations = categorize_tokens(vocab)\n",
        "            gt_symbols = [token for token in ground_truth_tokens if token in symbols]\n",
        "            gt_relations = [token for token in ground_truth_tokens if token in relations]\n",
        "\n",
        "            total_symbol_edit_distance += symbol_wer * len(gt_symbols)\n",
        "            total_symbol_length += len(gt_symbols)\n",
        "            total_relation_edit_distance += relation_wer * len(gt_relations)\n",
        "            total_relation_length += len(gt_relations)\n",
        "\n",
        "        # Calculate overall WER\n",
        "        wer = total_edit_distance / total_target_length if total_target_length > 0 else 0.0\n",
        "\n",
        "        # Calculate separate WERs\n",
        "        wer_sym = total_symbol_edit_distance / total_symbol_length if total_symbol_length > 0 else 0.0\n",
        "        wer_rel = total_relation_edit_distance / total_relation_length if total_relation_length > 0 else 0.0\n",
        "\n",
        "        return wer, wer_sym, wer_rel\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr) # Use self.hparams.lr\n",
        "        scheduler = ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode='min', # 'min' for loss, 'max' for accuracy\n",
        "            factor=self.hparams.lr_scheduler_factor, # Factor by which the learning rate will be reduced\n",
        "            patience=self.hparams.lr_scheduler_patience, # Number of epochs with no improvement after which learning rate will be reduced\n",
        "            verbose=True,\n",
        "            min_lr=1e-7 # Minimum learning rate\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"monitor\": self.hparams.monitor_metric, # Metric to monitor\n",
        "                \"interval\": \"epoch\", # Check scheduler conditions every epoch\n",
        "                \"frequency\": 1, # Check every 1 epoch\n",
        "            },\n",
        "        }"
      ],
      "metadata": {
        "trusted": true,
        "id": "OENCqCIjGomQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 7: Train the Model with PyTorch Lightning\n",
        "\n",
        "Read more about Training with PyTorch Lightning [here](https://lightning.ai/docs/pytorch/stable/common/trainer.html) and understand how to use the Trainer class to train the model.\n",
        "\n",
        "From the documentation:\n",
        "\n",
        "> The Lightning Trainer does much more than just “training”. Under the hood, it handles all loop details for you, some examples include:\n",
        "> - Automatically enabling/disabling grads\n",
        "> - Running the training, validation and test dataloaders\n",
        "> - Calling the Callbacks at the appropriate times\n",
        "> - Putting batches and computations on the correct devices"
      ],
      "metadata": {
        "id": "9D8zzyWkGomQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **IMPORTANT**: You must config your WandB logger to log the training and validation metrics. Without this, your work will not be graded."
      ],
      "metadata": {
        "id": "lpBbmYgyGomQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_id = \"10423041\"  # TODO: replace with your student ID\n",
        "api_key = \"2b821a6c6a9949625413bbb27b3f69453bc18b0a\"  # configure your wandb key here\n",
        "\n",
        "if api_key == \"\":\n",
        "    raise ValueError(\"Please set your wandb key in the code or in the environment variable WANDB_API_KEY\")\n",
        "else:\n",
        "    print(\"WandB API key is set. Proceeding with login...\")\n",
        "\n",
        "wandb.login(key=api_key)\n",
        "vocab = Vocab('vocab.json')\n",
        "decoder = GreedyCTCDecoder(vocab)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_rA8biO6GomQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7be2654-89f9-4df8-befd-4d1d69965c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WandB API key is set. Proceeding with login...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m10423041\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.002\n",
        "hidden_size = 256\n",
        "num_layer = 2\n",
        "max_epochs = 15\n",
        "batch_size = 16\n",
        "\n",
        "wandb_logger = WandbLogger(\n",
        "    entity=\"cuong-nt-vgu-ai-2025\",  # DO NOT CHANGE THIS\n",
        "    project=\"math_online_2025\", # DO NOT CHANGE THIS\n",
        "    name=f\"{student_id}_run_herrcult69_SemiFinal\",\n",
        "    config={\n",
        "        \"student_id\": student_id,  # DO NOT CHANGE THIS\n",
        "        \"model\": \"LSTM_TemporalClassification\",\n",
        "        # Architecture Hyperparameters\n",
        "        \"input_size\": 4,\n",
        "        \"hidden_size\": hidden_size,\n",
        "        \"num_layers\": num_layer,\n",
        "        \"num_classes\": 109,\n",
        "        \"bidirectional\": True,\n",
        "\n",
        "        # Training Hyperparameters\n",
        "        \"learning_rate\": lr,\n",
        "        \"batch_size\": batch_size,  # Start smaller for CTC convergence\n",
        "        \"max_epochs\": max_epochs,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"weight_decay\": 1e-4,\n",
        "\n",
        "        # Data Hyperparameters\n",
        "        \"num_workers\": 4,\n",
        "        \"pin_memory\": True,\n",
        "\n",
        "        # CTC Loss Hyperparameters\n",
        "        \"blank_token_idx\": 0,\n",
        "        \"ctc_reduction\": \"mean\",\n",
        "        \"zero_infinity\": True,\n",
        "\n",
        "        # WER log\n",
        "        \"monitor_metric\": \"val_wer\"\n",
        "    },\n",
        "    log_model=True,\n",
        "    save_dir=\"wandb_logs\",\n",
        "    reinit=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    callbacks = [\n",
        "        LearningRateMonitor(logging_interval='step'),\n",
        "        ModelCheckpoint(filename='{epoch}-{val_wer:.4f}', save_top_k=5, monitor='val_wer', mode='min'),\n",
        "        EarlyStopping(monitor='val_wer', min_delta=0.001, patience=8, verbose=True, mode='min', strict=True)\n",
        "    ],\n",
        "    logger = wandb_logger,\n",
        "    check_val_every_n_epoch=1,\n",
        "    fast_dev_run=True,  # enable for testing model\n",
        "    default_root_dir='checkpoint',\n",
        "    deterministic=False,\n",
        "    max_epochs=max_epochs,\n",
        "    log_every_n_steps=50,\n",
        "    devices = \"auto\",\n",
        "    gradient_clip_val=0.5,\n",
        "    gradient_clip_algorithm=\"norm\",\n",
        ")\n",
        "model = MathOnlineModel(lr=lr, hidden_size=hidden_size, num_layers=num_layer, constraint_weight=0.1)\n",
        "# model = MathOnlineModel.load_from_checkpoint('/content/wandb_logs/math_online_2025/ovbz3id1/checkpoints/epoch=9-val_wer=0.1645.ckpt', lr = lr)\n",
        "\n",
        "dm = InkmlDataset_PL(\n",
        "    root_dir='dataset/crohme2019',\n",
        "    train_annotation='dataset/crohme2019_train.txt',\n",
        "    validation_annotation='dataset/crohme2019_valid.txt',\n",
        "    test_annotation='dataset/crohme2019_test.txt',\n",
        "    vocab_file='vocab.json',\n",
        "    batch_size=batch_size,\n",
        "    num_workers=8\n",
        ")\n",
        "\n",
        "try:\n",
        "    trainer.fit(model, dm)\n",
        "    print(\"Training completed successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Training failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    wandb.finish()\n",
        "    print(\"WandB run finished\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "tAkmrItVGomQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "cc3520da-ba6a-45ec-9ea7-42cad21c43ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CUDACTCDecoder' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-28-2749299393.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mgradient_clip_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"norm\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMathOnlineModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;31m# model = MathOnlineModel.load_from_checkpoint('/content/wandb_logs/math_online_2025/ovbz3id1/checkpoints/epoch=9-val_wer=0.1645.ckpt', lr = lr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-26-595246208.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lr, input_size, output_size, hidden_size, num_layers, decoder, constraint_weight, lr_scheduler_patience, lr_scheduler_factor, monitor_metric, use_cuda_decoder, beam_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vocab.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_cuda_decoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCUDACTCDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✓ Using CUDA CTC Decoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CUDACTCDecoder' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "7iGdL8XziZYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements:**\n",
        "- Validation loss (val_loss < 0.7)\n",
        "\n",
        "**Tips on training:**\n",
        "- Debug with **fast_dev_run**:\n",
        "Before run the training process, it is better to make a quick check of training and validation loop. Set fast_dev_run=True, then run the trainer and check if there is any bug exist.\n",
        "- Training initially with **small batch size**:\n",
        "In practice, training with CTC loss converges slowly for large batch size. To accelerate convergence, training with small batch size first, save model, then, train with large batch size.\n",
        "- Train more epochs by setting:\n",
        "\n",
        "```python\n",
        "trainer = Trainer(\n",
        "    ...\n",
        "    max_epochs=20,\n",
        "    ...\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "afGbzkoIGomQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 8: Test your model\n",
        "\n",
        "Run the test set and check the accuracy of your model. The test set is used to evaluate the performance of the model on unseen data."
      ],
      "metadata": {
        "id": "QSITSKLPGomQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    devices=1,\n",
        "    logger=False,  # Disable logging for testing\n",
        "    enable_checkpointing=False,  # Disable checkpointing for testing\n",
        ")\n",
        "try:\n",
        "    # Load the model from a checkpoint\n",
        "    model = MathOnlineModel.load_from_checkpoint(\n",
        "    \"/content/wandb_logs/math_online_2025/skug9d31/checkpoints/epoch=2-val_wer=0.1118.ckpt\",)\n",
        "    print(\"✓ Model loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error loading model: {e}\")\n",
        "    print(\"Make sure you have a trained checkpoint file\")\n",
        "\n",
        "\n",
        "dm = InkmlDataset_PL(\n",
        "    root_dir=\"dataset/crohme2019\",\n",
        "    train_annotation=\"\",  # Empty for testing\n",
        "    validation_annotation=\"\",    # Empty for testing\n",
        "    test_annotation=\"dataset/crohme2019_test.txt\",  # Only test annotation needed\n",
        "    vocab_file=\"vocab.json\",\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2  # Reduced for stability\n",
        ")\n",
        "\n",
        "# Step 5: Run the test\n",
        "print(\"Starting model testing...\")\n",
        "try:\n",
        "    test_results = trainer.test(model, datamodule=dm)\n",
        "    print(\"✓ Testing completed successfully\")\n",
        "    print(f\"Test results: {test_results}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error during testing: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "2ad1639b7138461f8ff12074bd44b17e",
            "c077bfe974a443d4be019332491c1e7d",
            "3c9e32773723453aa3bbcd34e94db4bd",
            "70b9fadcbd354676833e00978f2a8a65",
            "f6b51678e2f74c79ad71b72a2108b51e",
            "ef802be26b1c4067a29c56fae5f85267",
            "07fbe5d72310480bad590611c27fee4e",
            "dd25c89e596f4d769f9718138823583b",
            "5b50e9afef654e9d8fceb3e59b246faa",
            "131765c097384fe6b35137554455cfca",
            "9e9538f0f03f40a9a3cedb8ce1a904f0"
          ]
        },
        "id": "tYSgb-6WFpi8",
        "outputId": "55c10105-013a-4993-d60d-e82ce0c5815f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model loaded successfully\n",
            "Starting model testing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ad1639b7138461f8ff12074bd44b17e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.527968168258667    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_wer         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11174412071704865   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test_wer_rel       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0898263156414032    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test_wer_sym       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1302817016839981    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.527968168258667     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_wer          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11174412071704865    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_wer_rel        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0898263156414032     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_wer_sym        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1302817016839981     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Testing completed successfully\n",
            "Test results: [{'test_loss': 0.527968168258667, 'test_wer': 0.11174412071704865, 'test_wer_sym': 0.1302817016839981, 'test_wer_rel': 0.0898263156414032}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 9: Inference\n",
        "\n",
        "The output of networks need to process by a decoding step.\n",
        "\n",
        "- Greedy decode: Your task is to implement greedy decoding method. Which converts the output into a string of symbols and relations (same form with labels). Greedy decoder produce the best path by removing consecutive repeated symbols/relations and then remove \\<blank\\>\n",
        "\n",
        "> **TASK**: Implement the greedy decoder for the model output.\n",
        "\n",
        "Based on GreedyCTCDecoder class from this [link](https://pytorch.org/audio/main/tutorials/asr_inference_with_ctc_decoder_tutorial.html#greedy-decoder), write decoding for an output. Your implementation should handle the output of the model and convert it into a string of symbols and relations, ensuring to remove consecutive repeated symbols/relations and the blank token."
      ],
      "metadata": {
        "id": "pm8LQ8zPGomQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GreedyCTCDecoder(torch.nn.Module):\n",
        "    def __init__(self, vocab):\n",
        "        super().__init__()\n",
        "        self.vocab = vocab\n",
        "        self.blank = vocab.char2idx[\"\"]  # Fixed: use char2idx instead of word2index\n",
        "\n",
        "    def forward(self, emission: torch.Tensor) -> list:\n",
        "\n",
        "        # Get the best path (indices with highest probability at each timestep)\n",
        "        indices = torch.argmax(emission, dim=-1)  # Shape: [seq_len]\n",
        "\n",
        "        # Remove consecutive duplicates\n",
        "        collapsed_indices = []\n",
        "        previous_idx = None\n",
        "\n",
        "        for idx in indices:\n",
        "            idx_item = idx.item()\n",
        "            if idx_item != previous_idx:  # Only add if different from previous\n",
        "                collapsed_indices.append(idx_item)\n",
        "                previous_idx = idx_item\n",
        "\n",
        "        # Remove blank tokens\n",
        "        filtered_indices = [idx for idx in collapsed_indices if idx != self.blank]\n",
        "\n",
        "        #Convert indices back to tokens using vocabulary\n",
        "        output_seq_list = self.vocab.decode(filtered_indices)\n",
        "\n",
        "        return output_seq_list"
      ],
      "metadata": {
        "trusted": true,
        "id": "W_b6FuMoGomQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you can test the output of your model here"
      ],
      "metadata": {
        "id": "job5znglGomQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model_checkpoint_path):\n",
        "    # Load trained model\n",
        "    model = MathOnlineModel.load_from_checkpoint(model_checkpoint_path)\n",
        "    model.eval()\n",
        "    # Determine the device the model is on\n",
        "    device = next(model.parameters()).device\n",
        "    print(f\"Model is on device: {device}\")\n",
        "\n",
        "    # Load vocabulary and dataset\n",
        "    vocab = Vocab('vocab.json')\n",
        "    dataset = InkmlDataset(\n",
        "        annotation=\"dataset/crohme2019_test.txt\",\n",
        "        root_dir=\"dataset/crohme2019\",\n",
        "        vocab=vocab\n",
        "    )\n",
        "\n",
        "    # Create decoder\n",
        "    greedy_decoder = GreedyCTCDecoder(vocab)\n",
        "    cuda_ctc_decoder = CUDACTCDecoder(vocab)\n",
        "    use_cuda = True\n",
        "\n",
        "    # Get a sample\n",
        "    feature, label, input_len, label_len = dataset[0]\n",
        "\n",
        "    # Add batch dimension\n",
        "    feature_batch = feature.unsqueeze(0)  # Shape: [1, seq_len, 4]\n",
        "    feature_batch = feature_batch.to(device)\n",
        "    # Model prediction\n",
        "    with torch.no_grad():\n",
        "        log_probs = model(feature_batch)  # Shape: [1, seq_len, num_classes]\n",
        "\n",
        "        # Remove batch dimension for decoder\n",
        "        emission = log_probs.squeeze(0)  # Shape: [seq_len, num_classes]\n",
        "\n",
        "        # Decode\n",
        "        if use_cuda:\n",
        "            decoded_output = cuda_ctc_decoder.forward(emission)\n",
        "        else:\n",
        "            decoded_output = greedy_decoder.forward(emission)\n",
        "\n",
        "    # Compare with ground truth\n",
        "    ground_truth = vocab.decode(label.tolist())\n",
        "\n",
        "    print(f\"Ground truth: {ground_truth}\")\n",
        "    print(f\"Predicted:    {decoded_output}\")\n",
        "\n",
        "    return decoded_output, ground_truth\n",
        "\n",
        "# Example usage (uncomment when you have a trained model):\n",
        "decoded, truth = test_model('/content/wandb_logs/math_online_2025/skug9d31/checkpoints/epoch=2-val_wer=0.1118.ckpt')\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "vnGy07ShGomR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e85da4-cb99-4afe-f6b7-3cc2ca43599b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is on device: cuda:0\n",
            "Ground truth: ['4', 'Right', 'n', 'Right', '-', 'Right', '4', 'Right', ')', 'NoRel', '(', 'NoRel', '-', 'NoRel', '2', 'Right', 'n', 'Right', '-', 'Right', '1', 'Right', ')', 'NoRel', '(', 'NoRel', '=', 'Right', '2', 'Right', 'n', 'Right', '-', 'Right', '3']\n",
            "Predicted:    ['4', 'Sub', 'n', 'NoRel', '-', 'Right', '4', 'Right', ')', 'NoRel', '(', 'NoRel', '-', 'Right', '2', 'Right', 'n', 'Right', '-', 'Right', '1', 'Right', ')', 'NoRel', '(', 'NoRel', '=', 'Right', '2', 'Right', 'n', 'Right', '-', 'Right', '3']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 10: Implement calculation metric for training"
      ],
      "metadata": {
        "id": "x6ps24sSGomR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_edit_distance(predicted_sequence, label_sequence):\n",
        "\n",
        "    len_pred = len(predicted_sequence)\n",
        "    len_label = len(label_sequence)\n",
        "\n",
        "    distance_grid = [[0] * (len_label + 1) for _ in range(len_pred + 1)]\n",
        "    for j in range(len_label + 1):\n",
        "        distance_grid[0][j] = j\n",
        "\n",
        "    for i in range(len_pred + 1):\n",
        "        distance_grid[i][0] = i\n",
        "\n",
        "    for i in range(1, len_pred + 1):\n",
        "        for j in range(1, len_label + 1):\n",
        "            sub_cost = 0 if predicted_sequence[i - 1] == label_sequence[j - 1] else 1\n",
        "            delete_cost = distance_grid[i - 1][j] + 1\n",
        "            insert_cost = distance_grid[i][j - 1] + 1\n",
        "            substitution_path_cost = distance_grid[i - 1][j - 1] + sub_cost\n",
        "\n",
        "            distance_grid[i][j] = min(delete_cost, insert_cost, substitution_path_cost)\n",
        "\n",
        "    return distance_grid[len_pred][len_label]\n",
        "# Test your implementation\n",
        "assert (\n",
        "    edit_distance(\n",
        "        [\n",
        "            \"\\\\phi\",\n",
        "            \"Right\",\n",
        "            \"(\",\n",
        "            \"Right\",\n",
        "            \"0\",\n",
        "            \"Right\",\n",
        "            \"(\",\n",
        "            \"Right\",\n",
        "            \"n\",\n",
        "            \"Right\",\n",
        "            \")\",\n",
        "            \"Right\",\n",
        "            \")\",\n",
        "        ],\n",
        "        [\n",
        "            \"\\\\phi\",\n",
        "            \"Right\",\n",
        "            \"(\",\n",
        "            \"Right\",\n",
        "            \"\\\\phi\",\n",
        "            \"Right\",\n",
        "            \"(\",\n",
        "            \"Right\",\n",
        "            \"n\",\n",
        "            \"Right\",\n",
        "            \")\",\n",
        "            \"Right\",\n",
        "            \")\",\n",
        "        ],\n",
        "    )\n",
        "    == 1\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "9aJFFU9mGomR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **TASK**: Implement word error rate metric (wer) for training,  validation and testing in your model.\n",
        ">\n",
        "> $wer = \\frac{total\\ edit\\ distance (predict\\ sequence,\\ target\\ sequence)}{total\\ target\\ sequence\\ length}$\n"
      ],
      "metadata": {
        "id": "seSAUJUNGomR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps to process:**\n",
        "\n",
        "- Decode the predicted sequences to obtain the text output.\n",
        "- Calculate the total edit distance between the predicted and target sequences.\n",
        "- Compute the word error rate using the formula provided.\n",
        "- Log the WER metric during training and validation.\n",
        "\n",
        "**Continue to train the model**\n",
        "\n",
        "- Load the latest trained model:\n",
        "\n",
        "```\n",
        "model = MathOnlineModel.load_from_checkpoint('path/to/your/checkpoint.ckpt')\n",
        "```\n",
        "- Change config of ModelCheckPoint to monitor the new metric (val_wer) instead.\n",
        "\n",
        "```\n",
        "        ModelCheckpoint(filename='{epoch}-{val_loss:.4f}', save_top_k=5, monitor='val_loss', mode='min')\n",
        "        \n",
        "      --> ModelCheckpoint(filename='{epoch}-{val_wer:.4f}', save_top_k=5, monitor='val_wer', mode='min'),\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "lGGm5JufGomR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def visualize_model_prediction(model, dataset, sample_idx=0, vocab_file='vocab.json'):\n",
        "\n",
        "    model.eval()\n",
        "    # Determine the device the model is on\n",
        "    device = next(model.parameters()).device\n",
        "    print(f\"Model is on device: {device}\")\n",
        "\n",
        "\n",
        "    vocab = Vocab(vocab_file)\n",
        "\n",
        "    feature, label, _, _ = dataset[sample_idx]\n",
        "    feature_batch = feature.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        log_probs = model(feature_batch)\n",
        "        probs = torch.exp(log_probs).squeeze(0).cpu().numpy()\n",
        "\n",
        "    blank_id = 0\n",
        "    non_blank_probs = 1 - probs[:, blank_id]\n",
        "\n",
        "    decoder = GreedyCTCDecoder(vocab)\n",
        "    predicted_tokens_final = decoder.forward(log_probs.squeeze(0))\n",
        "    ground_truth_tokens = vocab.decode(label.tolist())\n",
        "\n",
        "    seq_len = probs.shape[0]\n",
        "    timesteps = np.arange(seq_len)\n",
        "\n",
        "    predicted_indices = np.argmax(probs, axis=1)\n",
        "\n",
        "    label_positions = []\n",
        "    label_texts = []\n",
        "    last_idx = -1\n",
        "\n",
        "    for i, current_idx in enumerate(predicted_indices):\n",
        "        if current_idx != blank_id and current_idx != last_idx:\n",
        "            label_positions.append(i)\n",
        "            try:\n",
        "                token = vocab.decode([current_idx])[0]\n",
        "            except Exception:\n",
        "                token = '?'\n",
        "\n",
        "            if len(token) > 8:\n",
        "                token = token[:6] + '..'\n",
        "            label_texts.append(token)\n",
        "        last_idx = current_idx\n",
        "\n",
        "    # --- Plot Creation ---\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(40, 5))\n",
        "\n",
        "    # Plot the non-blank probability line\n",
        "    ax.plot(timesteps, non_blank_probs, label='Non-Blank Probability')\n",
        "    # Fill the area under the curve\n",
        "    # ax.fill_between(timesteps, 0, non_blank_probs, alpha=0.3)\n",
        "\n",
        "    # Set x-axis ticks and labels based on predicted tokens\n",
        "    for pos in label_positions:\n",
        "        ax.axvline(x=pos, color='red', linestyle='--', linewidth=0.8)\n",
        "\n",
        "    # 3. Place text with collision avoidance\n",
        "    # Determines minimum separation between labels in data coordinates. Tune as needed.\n",
        "    min_x_separation = 0.02 * seq_len\n",
        "    last_text_x = -np.inf # Keep track of the last label's position\n",
        "\n",
        "    # Get a good y-position below the axis for the labels\n",
        "    y_pos_text = ax.get_ylim()[0] - 0.1\n",
        "\n",
        "    for pos, text in zip(label_positions, label_texts):\n",
        "        # Nudge the text position to the right if it's too close to the previous one\n",
        "        text_x = max(pos, last_text_x + min_x_separation)\n",
        "\n",
        "        ax.text(text_x, y_pos_text, text,\n",
        "                ha='center', # Horizontal alignment\n",
        "                va='top',    # Vertical alignment\n",
        "                rotation=45,\n",
        "                color=\"red\",\n",
        "                fontsize=20)\n",
        "        last_text_x = text_x\n",
        "\n",
        "    # --- Print Final Results ---\n",
        "    print(f\"Decoded Predicted Sequence: {' '.join(predicted_tokens_final)}\")\n",
        "    print(f\"Ground Truth Sequence: {' '.join(ground_truth_tokens)}\")\n",
        "\n",
        "\n",
        "def test_visualization():\n",
        "    model_path = '/content/epoch=2-val_wer=0.1118.ckpt'\n",
        "    model = MathOnlineModel.load_from_checkpoint(model_path)\n",
        "    model.cpu()\n",
        "\n",
        "    # Load dataset\n",
        "    vocab = Vocab('vocab.json')\n",
        "    dataset = InkmlDataset(\n",
        "        annotation=\"dataset/crohme2019_test.txt\",\n",
        "        root_dir=\"dataset/crohme2019\",\n",
        "        vocab=vocab\n",
        "    )\n",
        "\n",
        "    visualize_model_prediction(model, dataset, sample_idx=77)\n",
        "# Run the visualization\n",
        "test_visualization()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "cje65BpHBgGk",
        "outputId": "3deeffe7-477d-4bd4-8ed8-5d9a85663434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is on device: cpu\n",
            "Decoded Predicted Sequence: a Right \\neq Right - Right 5\n",
            "Ground Truth Sequence: a Right \\neq Right - Right b\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 4000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bonus 4\n",
        "class CUDACTCDecoder:\n",
        "    def __init__(self, vocab, beam_size=10):\n",
        "        self.vocab = vocab\n",
        "        self.beam_size = beam_size\n",
        "        self.blank_id = vocab.char2idx[\"\"]\n",
        "        self.greedy_decoder = GreedyCTCDecoder(vocab)\n",
        "\n",
        "        # Create tokens list (vocabulary without blank)\n",
        "        self.tokens = []\n",
        "        for idx in range(len(vocab.char2idx)):\n",
        "            if idx != self.blank_id:\n",
        "                token = vocab.decode([idx])[0]\n",
        "                self.tokens.append(token)\n",
        "\n",
        "        # Initialize the CUDA CTC decoder\n",
        "        try:\n",
        "            self.decoder = ctc_decoder(\n",
        "                lexicon=None,  # No lexicon for mathematical expressions\n",
        "                tokens=self.tokens,\n",
        "                lm=None,\n",
        "                nbest=1,  # Return best hypothesis\n",
        "                beam_size=self.beam_size,\n",
        "                blank_token=\"\",\n",
        "                sil_token=\"\",\n",
        "                unk_word=\"<unk>\",\n",
        "                log_add=False,\n",
        "            )\n",
        "            print(\"CUDA CTC Decoder initialized successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to initialize CUDA CTC Decoder: {e}\")\n",
        "            print(\"Falling back to Greedy decoder...\")\n",
        "            self.decoder = None\n",
        "\n",
        "    def decode(self, log_probs):\n",
        "        if self.decoder is None:\n",
        "            # Fallback to greedy decoding\n",
        "            log_probs_2d = log_probs.squeeze(0) if log_probs.dim() == 3 else log_probs\n",
        "            return self._greedy_decode(log_probs_2d)\n",
        "\n",
        "        try:\n",
        "            if log_probs.dim() == 2:\n",
        "                # Add batch dimension: [seq_len, num_classes] -> [1, seq_len, num_classes]\n",
        "                log_probs = log_probs.unsqueeze(0)\n",
        "\n",
        "            # Move to CPU if on GPU\n",
        "            log_probs_cpu = log_probs.cpu()\n",
        "            beam_results = self.decoder(log_probs_cpu)\n",
        "\n",
        "            # Extract best hypothesis\n",
        "            if beam_results and len(beam_results[0]) > 0:\n",
        "                best_result = beam_results[0][0]  # First batch, first hypothesis\n",
        "                decoded_tokens = best_result.tokens\n",
        "                return decoded_tokens\n",
        "            else:\n",
        "                return []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"CUDA CTC Decoder failed: {e}\")\n",
        "            print(\"Falling back to greedy decoder...\")\n",
        "            return self._greedy_decode(log_probs.squeeze(0) if log_probs.dim() == 3 else log_probs)\n",
        "\n",
        "    def _greedy_decode(self, log_probs):\n",
        "        return self.greedy_decoder(log_probs)\n",
        "\n",
        "    def forward(self, emission):\n",
        "        return self.decode(emission)"
      ],
      "metadata": {
        "id": "sHGmqs6oYS4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTex36saaGHS",
        "outputId": "04d4e162-d95c-451b-a594-de10e611294a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 108 clean tokens for CUDA decoder\n",
            "Blank token (index 0) excluded from CUDA tokens\n",
            "✗ Fixed CUDA decoder failed: get_index(): incompatible function arguments. The following argument types are supported:\n",
            "    1. (self: flashlight.lib.text.flashlight_lib_text_dictionary.Dictionary, entry: str) -> int\n",
            "\n",
            "Invoked with: <flashlight.lib.text.flashlight_lib_text_dictionary.Dictionary object at 0x7f6a22dabab0>, None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/parsing.py:209: Attribute 'decoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['decoder'])`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CUDA CTC Decoder Test ===\n",
            "Ground truth: ['4', 'Right', 'n', 'Right', '-', 'Right', '4', 'Right', ')', 'NoRel', '(', 'NoRel', '-', 'NoRel', '2', 'Right', 'n', 'Right', '-', 'Right', '1', 'Right', ')', 'NoRel', '(', 'NoRel', '=', 'Right', '2', 'Right', 'n', 'Right', '-', 'Right', '3']\n",
            "CUDA decoded: ['4', 'Sub', 'n', 'NoRel', '-', 'Right', '4', 'Right', ')', 'NoRel', '(', 'NoRel', '-', 'Right', '2', 'Right', 'n', 'Right', '-', 'Right', '1', 'Right', ')', 'NoRel', '(', 'NoRel', '=', 'Right', '2', 'Right', 'n', 'Right', '-', 'Right', '3']\n",
            "WER: 0.0857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJqRR3ifahok",
        "outputId": "bcd40b44-f068-4e11-fc68-45670f1dfe4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Vocabulary Inspection ===\n",
            "Total tokens: 109\n",
            "Blank token at index 0: ''\n",
            "\n",
            "Special LaTeX tokens (35):\n",
            "  46: '\\Delta'\n",
            "  47: '\\alpha'\n",
            "  48: '\\beta'\n",
            "  49: '\\cos'\n",
            "  50: '\\div'\n",
            "  51: '\\exists'\n",
            "  52: '\\forall'\n",
            "  53: '\\gamma'\n",
            "  54: '\\geq'\n",
            "  55: '\\gt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BONUS TASKS**\n",
        "\n",
        "The following tasks are optional and can be done for extra credit to the final exam.\n",
        "\n",
        "### **Bonus 1**: Add metric to evaluate accuracy of symbols and relations seperately *(+0.5pt)*\n",
        "\n",
        "**Add the metrics: wer for symbols and wer for relations**\n",
        "```\n",
        "self.log('wer_sym',...)\n",
        "self.log('wer_rel',...)\n",
        "```\n",
        "\n",
        "### **Bonus 2**: Modify loss function to constraint the output of relations at the time step of pen-up *(+1pt)*\n",
        "Modify loss function to constrain the output of relations at the timestep of pen-up.\n",
        "\n",
        "The idea: Provide a masked sequence such that the position of pen-up is masked, the additional loss would penaltize all the relations output to the timestep that has been masked.\n",
        "\n",
        "\n",
        "**Loss function to constraint relation output**\n",
        "\n",
        "```\n",
        "pen_down: a masked sequence, where len(pen_down) = len(input_sequence)\n",
        "        and pen_down[t] == 1 (pen down), pen_down[t] == 0 (pen up)\n",
        "p_rel: total probability of relation outputs for every time step t, len(p_rel) = len(input_sequence), p_rel[t] = sum(p[t][rel] for rel in ['Sub', 'Sup', 'Above', ...])\n",
        "\n",
        "The loss is defined as:\n",
        "\n",
        "    L_{constraint} = -log(1 - sum(p_rel * pen_down))\n",
        "    \n",
        "Explanation:\n",
        "\n",
        "    Minimize L_{constraint} (value range of (-inf, 0)) would make maximize of (1 - sum(p_rel * pen_down)), or making sum(p_rel * mask) -> 0, then it will penalize the relation output on pen_down timesteps.\n",
        "```\n",
        "\n",
        "**Apply constraint loss function with ctc loss**\n",
        "\n",
        "```\n",
        "    L = loss_{ctc} + \\lambda * L_{constraint}\n",
        "    \n",
        "where \\lambda is a weighted parameter to control balance between the two losses.\n",
        "   \n",
        "```\n",
        "\n",
        "\n",
        "You can also find it in a published paper here, section 3.4:\n",
        "https://arxiv.org/pdf/2105.10156\n",
        "\n",
        "### **Bonus 3**: Visualize model prediction by timesteps and probability of softmax outputs *(+0.5pt)*\n",
        "\n",
        "![alt text](https://github.com/fuisl/crohme-ctc/blob/6722b97ec2000afcd16068220f0b1b83b3134ff8/assets/graph_with_prob.png?raw=true)\n",
        "\n",
        "### **Bonus 4**: Use CUDA CTC Decoder to optimize decoding process in model *(+0.5pt)*\n",
        "\n",
        "Follow the instructions via this [link](https://pytorch.org/audio/main/tutorials/asr_inference_with_ctc_decoder_tutorial.html#cuda-ctc-decoder) to implement CUDA CTC decoder in your model."
      ],
      "metadata": {
        "id": "o9YVut4FGomR"
      }
    }
  ]
}